# AI Image Screener  
>*A practical first-pass AI image screening system for modern workflows (2025)*

---

## 1. Overview

**AI Image Screener** is an MVP-grade, **unsupervised image screening system** designed to **identify images that require human review** based on statistical and physical patterns commonly associated with AI-generated imagery.

This system is **not a â€œperfect AI detector.â€**  
It is intentionally built as a **fast, transparent, first-pass screening tool** that helps teams reduce manual review workload by flagging *obviously suspicious* images at scale.

The product is particularly suited for:

- Content moderation pipelines  
- Journalism and media verification  
- Stock image platforms  
- Legal and compliance pre-screening  
- Marketing and brand-protection workflows  

---

## 2. Core Philosophy

### What this product *is*
- A **workflow efficiency tool**
- A **screening system**, not a verdict engine
- A **transparent and explainable detector**
- A **model-agnostic, unsupervised system**

### What this product *is not*
- âŒ A definitive â€œreal vs fakeâ€ classifier  
- âŒ A black-box deep learning detector  
- âŒ A system claiming near-perfect accuracy on 2025 AI models  

The system is built on a simple principle:  
**saving human time is more valuable than chasing perfect detection.**

---

## 3. Problem Statement

By 2025, high-quality AI image generators (e.g., DALLÂ·E 3, Gemini Imagen 3, Midjourney v6+) produce images that are often **indistinguishable to humans** and increasingly difficult for single-method detectors.

Most existing tools fail because they:
- Overpromise accuracy
- Provide ambiguous outputs (â€œuncertainâ€, â€œmaybe AIâ€)
- Rely on opaque ML models users do not trust
- Do not integrate into real operational workflows

---

## 4. Product Positioning

### The key insight

Users **do not need certainty** â€” they need **prioritization**.

Instead of asking:  
> *â€œIs this image AI or real?â€*

The system answers:  
> *â€œDoes this image require human review?â€*

---

## 5. Binary UX Model (Critical Design Decision)

The system intentionally provides **only two outcomes**, ensuring every result is actionable.

### ðŸŸ¢ LIKELY AUTHENTIC
- No significant AI-generation patterns detected
- Passed all screening checks
- **Does not guarantee authenticity**
- No immediate action required

### ðŸ”´ REVIEW REQUIRED
- One or more detection signals triggered
- Patterns consistent with AI generation
- Confidence score provided for prioritization
- **Manual verification recommended**

This avoids the UX failure of ambiguous or â€œuncertainâ€ results.

---

## 6. Detection Strategy  
### *(Multi-Signal, Unsupervised Ensemble)*

The system runs **multiple independent statistical detectors** on every image.  
Each detector targets a *different failure mode* of AI image generation.

Each metric produces:
- A **normalized anomaly score** in `[0.0 â€“ 1.0]`
- **Rich intermediate details** for explainability and reporting

### Implemented Metrics (`metrics/`)

| Metric | File | Purpose |
|-----|-----|-----|
| Gradient-Field PCA | `metrics/gradient_field_pca.py` | Detects lighting & gradient inconsistencies typical of diffusion |
| Frequency Analysis (FFT) | `metrics/frequency_analyzer.py` | Identifies unnatural spectral energy distributions |
| Noise Pattern Analysis | `metrics/noise_analyzer.py` | Detects missing or artificial sensor noise |
| Texture Statistics | `metrics/texture_analyzer.py` | Identifies overly smooth or uniform regions |
| Color Distribution | `metrics/color_analyzer.py` | Flags unnatural saturation and color histograms |

No single metric is relied upon in isolation.

---

## 7. Score Aggregation & Decision Logic

### Aggregation

All metric outputs are combined using a **weighted ensemble strategy**:

- Implemented in: `metrics/aggregator.py`
- Metric weights are configurable
- No single signal can dominate the final decision
- Robust to individual metric failure

### Thresholding

Final decisions are derived from calibrated thresholds:

- ðŸŸ¢ **LIKELY_AUTHENTIC** â†’ score below review cutoff  
- ðŸ”´ **REVIEW_REQUIRED** â†’ score above cutoff  

Thresholds and sensitivity modes are managed via:

- `features/threshold_manager.py`
  - Conservative / Balanced / Aggressive modes
  - Runtime threshold tuning
  - A/B calibration support

---

## 8. Explainability & Transparency

Every analysis result includes:

- Which metrics triggered
- Severity level per metric (PASSED / WARNING / FLAGGED)
- Human-readable explanations
- Optional forensic details for advanced users

This avoids black-box behavior and builds user trust.

---

## 9. Reporting & Export Capabilities

The system generates **production-ready reports without recomputation**.

### Reporters (`reporter/`)

| Format | File | Use Case |
|-----|-----|-----|
| CSV | `reporter/csv_reporter.py` | Workflow integration, moderation queues |
| JSON | `reporter/json_reporter.py` | APIs, automation, auditing |
| PDF | `reporter/pdf_reporter.py` | Legal, compliance, documentation |

All reporting is driven by:

- `features/detailed_result_maker.py`  
  (single source of truth for explanations, findings, and summaries)

---

## 10. Technical Architecture

### High-Level Processing Flow

```bash
Upload Image(s)
      â†“
Validation & Preprocessing (utils/)
      â†“
Parallel Metric Execution (metrics/)
      â†“
Score Aggregation (metrics/aggregator.py)
      â†“
Threshold Decision (features/threshold_manager.py)
      â†“
Detailed Result Assembly (features/detailed_result_maker.py)
      â†“
UI / Reports / API Output
```

---

### Backend & Frontend

**Backend**
- FastAPI (Python 3.11+)
- Async batch processing
- Parallel metric execution
- File-based caching (image hash)
- JSON / CSV / PDF outputs
- Clear API contracts (`docs/API.md`)

**Frontend**
- Single-page HTML (inline CSS + JS)
- Batch upload interface
- Live per-metric progress indicators
- Filterable results table
- One-click export actions

---

## 11. Project Structure

```bash
ai_image_screener/
â”œâ”€â”€ app.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ constants.py
â”‚   â””â”€â”€ schemas.py
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ gradient_field_pca.py
â”‚   â”œâ”€â”€ frequency_analyzer.py
â”‚   â”œâ”€â”€ noise_analyzer.py
â”‚   â”œâ”€â”€ texture_analyzer.py
â”‚   â”œâ”€â”€ color_analyzer.py
â”‚   â””â”€â”€ aggregator.py
â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ batch_processor.py
â”‚   â”œâ”€â”€ detailed_result_maker.py
â”‚   â””â”€â”€ threshold_manager.py
â”œâ”€â”€ reporter/
â”‚   â”œâ”€â”€ csv_reporter.py
â”‚   â”œâ”€â”€ json_reporter.py
â”‚   â””â”€â”€ pdf_reporter.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ image_processor.py
â”‚   â”œâ”€â”€ validators.py
â”‚   â””â”€â”€ helpers.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/
â”‚   â”œâ”€â”€ reports/
â”‚   â””â”€â”€ cache/
â”œâ”€â”€ ui/
â”œâ”€â”€ tests/
â””â”€â”€ docs/
```

---

## 12. Performance Expectations *(Honest)*

| Image Source | Expected Detection Rate |
|-------------|------------------------|
| Consumer AI tools (older / free) | 80â€“90% |
| Stable Diffusion (older variants) | 70â€“80% |
| Midjourney v5 / v6 | 55â€“70% |
| DALLÂ·E 3 / Gemini Imagen 3 | 40â€“55% |
| Post-processed AI images | 30â€“45% |
| False positives on real images | ~10â€“20% |

These rates are **appropriate for screening**, not final judgment.

---

## 13. Ethical & Legal Positioning

This system:

- Never claims **â€œrealâ€** or **â€œfakeâ€**
- Provides **probabilistic screening only**
- Encourages **human verification**
- Documents methodology **transparently**

This makes it suitable for:

- Legal workflows  
- Journalism  
- Enterprise moderation pipelines  

---

## 14. Intended Audience

- Content moderation teams  
- Journalism & media organizations  
- Stock photo platforms  
- Legal & compliance professionals  
- Researchers & educators  

---

## 15. Final Positioning Statement

**AI Image Screener is not an AI detector.**  

> It is a **first-pass screening system designed to save human time**. 
> It flags what needs review â€” **fast, explainable, and at scale**.