{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2d654dc-c431-420e-810a-a985de9172fd",
   "metadata": {},
   "source": [
    "# Unified AI vs Real Image Dataset Builder\n",
    "\n",
    "This notebook builds a **clean, labeled, unified dataset** for evaluating\n",
    "AI image detection systems.\n",
    "\n",
    "### Supported sources\n",
    "- HuggingFace datasets (DiffusionDB, COCO, OpenImages)\n",
    "- Kaggle public datasets (Midjourney, AI vs Real)\n",
    "- Unified output format:\n",
    "  - Normalized PNG images\n",
    "  - Size-limited (â‰¤1024px)\n",
    "  - Central metadata CSV\n",
    "\n",
    "### Output Structure\n",
    "\n",
    "```bash\n",
    "tests/dataset/\n",
    "â”œâ”€â”€ ai/\n",
    "â”œâ”€â”€ real/\n",
    "â”œâ”€â”€ raw_downloads/\n",
    "â”œâ”€â”€ metadata/dataset_index.csv\n",
    "```\n",
    "\n",
    "> âš ï¸ All datasets used are **public & legally accessible**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b43897-9ce5-4f20-8798-7b3aebdf1b36",
   "metadata": {},
   "source": [
    "## Required Dependencies\n",
    "\n",
    "Before running, ensure:\n",
    "\n",
    "```bash\n",
    "pip install datasets pillow tqdm kaggle pycocotools\n",
    "```\n",
    "\n",
    "Also configure Kaggle:\n",
    "\n",
    "```bash\n",
    "~/.kaggle/kaggle.json\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b9f50c-6158-47e9-89cf-5c279d9c63bb",
   "metadata": {},
   "source": [
    "## Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9147ace7-162f-4b0d-bd6d-0d92b9bad61e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Imports & Global Configuration\n",
    "# ===============================\n",
    "import os\n",
    "import csv\n",
    "import uuid\n",
    "import subprocess\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Directory Configuration\n",
    "# ===============================\n",
    "BASE_DIR       = Path(\"../tests/dataset\")\n",
    "AI_DIR         = BASE_DIR / \"ai\"\n",
    "REAL_DIR       = BASE_DIR / \"real\"\n",
    "RAW_DIR        = BASE_DIR / \"raw_downloads\"\n",
    "META_DIR       = BASE_DIR / \"metadata\"\n",
    "\n",
    "META_FILE      = META_DIR / \"dataset_index.csv\"\n",
    "\n",
    "TARGET_PER_DS  = 1000\n",
    "IMAGE_SIZE_MAX = 1024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329d1c09-0e9c-4bc2-8935-bd50941611c8",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "These helpers:\n",
    "- Ensure directory structure\n",
    "- Normalize images (RGB, resize, PNG)\n",
    "- Write metadata rows safely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b352e981-e456-40cf-be84-a1eb0f01ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dirs():\n",
    "    for d in [AI_DIR, REAL_DIR, RAW_DIR, META_DIR]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def normalize_and_save(image: Image.Image, path: Path):\n",
    "    \"\"\"\n",
    "    Normalize image to RGB PNG and limit size\n",
    "    \"\"\"\n",
    "    image = image.convert(\"RGB\")\n",
    "    image.thumbnail((IMAGE_SIZE_MAX, IMAGE_SIZE_MAX))\n",
    "    image.save(path, \n",
    "               format   = \"PNG\", \n",
    "               optimize = True,\n",
    "              )\n",
    "\n",
    "\n",
    "def write_meta(writer, **row):\n",
    "    writer.writerow(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c3bc3b-6bb6-414d-b3fe-85bc43d832c7",
   "metadata": {},
   "source": [
    "## Dataset Registry\n",
    "\n",
    "Defines **where data comes from** and **how it is labeled**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74106705-e2d6-411c-8193-8e02f5ee0fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace datasets (safe & stable)\n",
    "AI_DATASETS     = [{\"name\"      : \"diffusiondb\",\n",
    "                    \"hf_id\"     : \"poloclub/diffusiondb\",\n",
    "                    \"config\"    : \"2m_first_1k\",\n",
    "                    \"split\"     : \"train\",\n",
    "                    \"image_key\" : \"image\",\n",
    "                    \"label\"     : \"ai\",\n",
    "                    \"family\"    : \"diffusion\"\n",
    "                  }]\n",
    "        \n",
    "\n",
    "REAL_DATASETS   = [{\"name\"      : \"imagenette\",\n",
    "                    \"hf_id\"     : \"frgfm/imagenette\",\n",
    "                    \"config\"    : \"320px\",\n",
    "                    \"split\"     : \"train\",\n",
    "                    \"image_key\" : \"image\",\n",
    "                    \"label\"     : \"real\",\n",
    "                    \"family\"    : \"photographic\",\n",
    "                  }]\n",
    "\n",
    "# Kaggle datasets (public, non-scraped)\n",
    "KAGGLE_DATASETS = [{\"name\"      : \"ai_vs_real\",\n",
    "                    \"kaggle_id\" : \"tristanzhang32/ai-generated-images-vs-real-images\",\n",
    "                    \"label\"     : \"ai\",\n",
    "                    \"family\"    : \"mixed\"\n",
    "                   },\n",
    "                   {\"name\"      : \"midjourney\",\n",
    "                    \"kaggle_id\" : \"cyanex1702/midjourney-imagesprompt\",\n",
    "                    \"label\"     : \"ai\",\n",
    "                    \"family\"    : \"diffusion\"\n",
    "                   }\n",
    "                  ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4c6f3b-2a35-415b-9a35-ee52fd3d85be",
   "metadata": {},
   "source": [
    "## HuggingFace Dataset Processor\n",
    "\n",
    "Loads datasets via `datasets.load_dataset()` and saves images in unified format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9ea5276-65bb-49f5-a656-c00ceeb1f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hf_dataset(ds_cfg, root_dir, writer):\n",
    "    print(f\"\\nâ–¶ Loading HF dataset: {ds_cfg['name']}\")\n",
    "\n",
    "    ds      = load_dataset(ds_cfg[\"hf_id\"],\n",
    "                           **ds_cfg.get(\"hf_kwargs\", {}),\n",
    "                           name      = ds_cfg.get(\"config\"),\n",
    "                           split     = ds_cfg[\"split\"],\n",
    "                           streaming = ds_cfg.get(\"streaming\", False),\n",
    "                          )\n",
    "\n",
    "    out_dir = root_dir / ds_cfg[\"name\"]\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    count   = 0\n",
    "    \n",
    "    for row in tqdm(ds):\n",
    "        if (count >= TARGET_PER_DS):\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            image = row.get(ds_cfg[\"image_key\"])\n",
    "            if not isinstance(image, Image.Image):\n",
    "                continue\n",
    "\n",
    "            uid   = uuid.uuid4().hex\n",
    "            path  = out_dir / f\"{uid}.png\"\n",
    "\n",
    "            normalize_and_save(image, path)\n",
    "\n",
    "            write_meta(writer,\n",
    "                       id       = uid,\n",
    "                       filename = str(path),\n",
    "                       label    = ds_cfg[\"label\"],\n",
    "                       family   = ds_cfg[\"family\"],\n",
    "                       source   = ds_cfg[\"name\"],\n",
    "                      )\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6d23a0-fa98-4351-9e4e-99265a51e8ef",
   "metadata": {},
   "source": [
    "## Kaggle Dataset Downloader\n",
    "\n",
    "Requires:\n",
    "- Kaggle account\n",
    "- ~/.kaggle/kaggle.json configured\n",
    "\n",
    "No scraping. Fully legal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6eca5e6-0469-4af6-8af8-afe3036cb0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_kaggle_dataset(kaggle_id: str, out_dir: Path):\n",
    "    out_dir.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "    if any(out_dir.iterdir()):\n",
    "        print(f\"âœ” Kaggle dataset already present: {kaggle_id}\")\n",
    "        return\n",
    "\n",
    "    print(f\"â¬‡ Downloading Kaggle dataset: {kaggle_id}\")\n",
    "\n",
    "    subprocess.run([\"kaggle\", \"datasets\", \"download\",\n",
    "                    kaggle_id,\n",
    "                    \"-p\", str(out_dir),\n",
    "                    \"--unzip\"\n",
    "                   ],\n",
    "                   check = True,\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c971767-d20a-4fa3-949a-a655d712b2c1",
   "metadata": {},
   "source": [
    "## Folder Ingestor\n",
    "\n",
    "Converts **any folder of images** into the unified dataset format. \n",
    "Used for Kaggle & future web sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b648832e-5025-4851-af21-382051167a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_EXTS = {\".png\", \".jpg\", \".jpeg\", \".webp\"}\n",
    "\n",
    "def ingest_image_folder(src_dir, out_dir, writer, label, family, source):\n",
    "    images = [p for p in src_dir.rglob(\"*\") if p.suffix.lower() in IMAGE_EXTS]\n",
    "\n",
    "    out_dir.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "    for image_path in tqdm(images[:TARGET_PER_DS]):\n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "\n",
    "            uid   = uuid.uuid4().hex\n",
    "            dst   = out_dir / f\"{uid}.png\"\n",
    "\n",
    "            normalize_and_save(image, dst)\n",
    "\n",
    "            write_meta(writer,\n",
    "                       id       = uid,\n",
    "                       filename = str(dst),\n",
    "                       label    = label,\n",
    "                       family   = family,\n",
    "                       source   = source,\n",
    "                      )\n",
    "            \n",
    "        except Exception:\n",
    "            continue\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fccdc4-e593-4dbf-a71b-e5b826e4a27a",
   "metadata": {},
   "source": [
    "## Main Pipeline Execution\n",
    "\n",
    "This cell:\n",
    "- Builds directories\n",
    "- Processes HF datasets\n",
    "- Downloads & ingests Kaggle datasets\n",
    "- Writes unified metadata CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd8ef771-f39f-4d9d-8eaf-626ecc211141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â–¶ Loading HF dataset: diffusiondb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [05:30<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â–¶ Loading HF dataset: imagenette\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/itobuz/.cache/huggingface/modules/datasets_modules/datasets/frgfm--imagenette/38929285b8abcae5c1305418e9d8fea5dd6b189bbbd22caba5f5537c7fa0f01f (last modified on Mon Dec 22 15:06:36 2025) since it couldn't be found locally at frgfm/imagenette., or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce74ba00790b49fab546616010a4952d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/342M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcadae012cfa492f8e94ea1662cb8102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0d3ab402554b7489a01f883e4d6572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e65e45076104352951a4a71bd8d6da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d714e865ab2a43dcb43a33dcf0df2be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9469 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d1d87ad10548eebf9ba2709dbda441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3925 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                            | 1000/9469 [02:30<21:13,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ Downloading Kaggle dataset: tristanzhang32/ai-generated-images-vs-real-images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/itobuz/.conda/envs/mvp_env/bin/kaggle\", line 7, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/itobuz/.conda/envs/mvp_env/lib/python3.10/site-packages/kaggle/cli.py\", line 68, in main\n",
      "    out = args.func(**command_args)\n",
      "  File \"/Users/itobuz/.conda/envs/mvp_env/lib/python3.10/site-packages/kaggle/api/kaggle_api_extended.py\", line 1741, in dataset_download_cli\n",
      "    with self.build_kaggle_client() as kaggle:\n",
      "  File \"/Users/itobuz/.conda/envs/mvp_env/lib/python3.10/site-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
      "    username=self.config_values['username'],\n",
      "KeyError: 'username'\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['kaggle', 'datasets', 'download', 'tristanzhang32/ai-generated-images-vs-real-images', '-p', '../tests/dataset/raw_downloads/ai_vs_real', '--unzip']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 46\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Entry Point\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m KAGGLE_DATASETS:\n\u001b[1;32m     17\u001b[0m     raw_path \u001b[38;5;241m=\u001b[39m RAW_DIR \u001b[38;5;241m/\u001b[39m ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mdownload_kaggle_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkaggle_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# AI images\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     ingest_image_folder(src_dir \u001b[38;5;241m=\u001b[39m raw_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m                         out_dir \u001b[38;5;241m=\u001b[39m AI_DIR \u001b[38;5;241m/\u001b[39m ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     23\u001b[0m                         writer  \u001b[38;5;241m=\u001b[39m writer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m                         source  \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     27\u001b[0m                        )\n",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m, in \u001b[0;36mdownload_kaggle_dataset\u001b[0;34m(kaggle_id, out_dir)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâ¬‡ Downloading Kaggle dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkaggle_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkaggle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdownload\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                \u001b[49m\u001b[43mkaggle_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--unzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m               \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m               \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m              \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mvp_env/lib/python3.10/subprocess.py:526\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 526\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    527\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['kaggle', 'datasets', 'download', 'tristanzhang32/ai-generated-images-vs-real-images', '-p', '../tests/dataset/raw_downloads/ai_vs_real', '--unzip']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    ensure_dirs()\n",
    "\n",
    "    with open(META_FILE, \"w\", newline = \"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"id\", \"filename\", \"label\", \"family\", \"source\"])\n",
    "        writer.writeheader()\n",
    "\n",
    "        # HuggingFace datasets\n",
    "        for ds in AI_DATASETS:\n",
    "            process_hf_dataset(ds, AI_DIR, writer)\n",
    "\n",
    "        for ds in REAL_DATASETS:\n",
    "            process_hf_dataset(ds, REAL_DIR, writer)\n",
    "\n",
    "        # Kaggle datasets\n",
    "        for ds in KAGGLE_DATASETS:\n",
    "            raw_path = RAW_DIR / ds[\"name\"]\n",
    "            download_kaggle_dataset(ds[\"kaggle_id\"], raw_path)\n",
    "\n",
    "            # AI images\n",
    "            ingest_image_folder(src_dir = raw_path / \"ai\",\n",
    "                                out_dir = AI_DIR / ds[\"name\"],\n",
    "                                writer  = writer,\n",
    "                                label   = \"ai\",\n",
    "                                family  = ds[\"family\"],\n",
    "                                source  = ds[\"name\"],\n",
    "                               )\n",
    "\n",
    "            # REAL images\n",
    "            ingest_image_folder(src_dir = raw_path / \"real\",\n",
    "                                out_dir = REAL_DIR / ds[\"name\"],\n",
    "                                writer  = writer,\n",
    "                                label   = \"real\",\n",
    "                                family  = \"photographic\",\n",
    "                                source  = ds[\"name\"],\n",
    "                               )\n",
    "\n",
    "    print(\"\\nâœ… Dataset build complete\")\n",
    "    print(f\"ðŸ“„ Metadata saved at: {META_FILE}\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Entry Point\n",
    "# ===============================\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6e0834-7757-4daf-a8bc-37d58bc8debd",
   "metadata": {},
   "source": [
    "# Post-Processing Attack Generator\n",
    "\n",
    "This notebook applies **real-world post-processing attacks** to an existing\n",
    "image dataset to evaluate robustness of AI-image detectors.\n",
    "\n",
    "### Attacks Implemented\n",
    "- JPEG recompression (quality loss)\n",
    "- Resize / rescale (down + up)\n",
    "- Gaussian blur\n",
    "\n",
    "### Why this matters\n",
    "Most AI images in the wild are:\n",
    "- Screenshot\n",
    "- Re-encoded\n",
    "- Uploaded to social media\n",
    "- Slightly blurred or resized\n",
    "\n",
    "If a detector fails here, it fails in production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd680866-0f5c-4930-9262-5521317044fd",
   "metadata": {},
   "source": [
    "## Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62168b8-aa38-47c6-8a00-0bb31e8774fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Imports\n",
    "# ===============================\n",
    "\n",
    "import csv\n",
    "import uuid\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from PIL import ImageFilter\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Configuration\n",
    "# ===============================\n",
    "\n",
    "BASE_DIR       = Path(\"tests/dataset\")\n",
    "ATTACK_DIR     = BASE_DIR / \"attacked\"\n",
    "META_IN        = BASE_DIR / \"metadata/dataset_index.csv\"\n",
    "META_OUT       = BASE_DIR / \"metadata/dataset_index_attacked.csv\"\n",
    "\n",
    "ATTACK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "JPEG_QUALITIES = [95, 75, 50]\n",
    "RESIZE_SCALES  = [0.75, 0.5]\n",
    "BLUR_RADII     = [0.8, 1.5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1de132-8245-42c7-9a82-63d6f0c27270",
   "metadata": {},
   "source": [
    "## Load Existing Metadata\n",
    "\n",
    "We read the existing unified dataset index and create\n",
    "new samples **derived from originals**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49e5629-ba32-4736-b0ab-e81084f58b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata(path):\n",
    "    with open(path, newline=\"\") as f:\n",
    "        return list(csv.DictReader(f))\n",
    "\n",
    "\n",
    "records = load_metadata(META_IN)\n",
    "print(f\"Loaded {len(records)} original samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a0e31a-abdf-4564-8696-90aef3fc5ec4",
   "metadata": {},
   "source": [
    "## Attack Primitives\n",
    "\n",
    "Each function:\n",
    "- Takes a PIL Image\n",
    "- Returns a new PIL Image\n",
    "- Does **not** modify the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6027902-897a-4a3b-a806-e715fea43050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jpeg_attack(image: Image.Image, quality: int) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Simulate JPEG recompression\n",
    "    \"\"\"\n",
    "    buf = BytesIO()\n",
    "    image.save(buf, \n",
    "               format  = \"JPEG\", \n",
    "               quality = quality,\n",
    "              )\n",
    "    \n",
    "    buf.seek(0)\n",
    "    return Image.open(buf).convert(\"RGB\")\n",
    "\n",
    "\n",
    "def resize_attack(image: Image.Image, scale: float) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Downscale and upscale image\n",
    "    \"\"\"\n",
    "    w, h         = image.size\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    image_small  = image.resize((new_w, new_h), Image.BICUBIC)\n",
    "    \n",
    "    return image_small.resize((w, h), Image.BICUBIC)\n",
    "\n",
    "\n",
    "def blur_attack(image: Image.Image, radius: float) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Apply Gaussian blur\n",
    "    \"\"\"\n",
    "    return image.filter(ImageFilter.GaussianBlur(radius))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d3ca44-b497-4397-bd35-04db9041d1e4",
   "metadata": {},
   "source": [
    "## Attack Application Pipeline\n",
    "\n",
    "For each original image:\n",
    "- Apply all attack variants\n",
    "- Save attacked images\n",
    "- Write **attack-aware metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c702ab79-68b1-4191-8e87-f26ad0227348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_attacks(records, writer):\n",
    "    for r in tqdm(records):\n",
    "        src_path = Path(r[\"filename\"])\n",
    "        \n",
    "        if not src_path.exists():\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img = Image.open(src_path).convert(\"RGB\")\n",
    "            \n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        base_name = src_path.stem\n",
    "        label     = r[\"label\"]\n",
    "\n",
    "        out_base  = ATTACK_DIR / r[\"source\"]\n",
    "        out_base.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "        # --- JPEG ---\n",
    "        for q in JPEG_QUALITIES:\n",
    "            attacked = jpeg_attack(img, q)\n",
    "            uid      = uuid.uuid4().hex\n",
    "            out_path = out_base / f\"{uid}.png\"\n",
    "\n",
    "            attacked.save(out_path, optimize = True)\n",
    "\n",
    "            writer.writerow({**r,\n",
    "                             \"id\"        : uid,\n",
    "                             \"filename\"  : str(out_path),\n",
    "                             \"attack\"    : f\"jpeg_q{q}\",\n",
    "                             \"parent_id\" : r[\"id\"]\n",
    "                           })\n",
    "\n",
    "        # --- Resize ---\n",
    "        for s in RESIZE_SCALES:\n",
    "            attacked = resize_attack(img, s)\n",
    "            uid      = uuid.uuid4().hex\n",
    "            out_path = out_base / f\"{uid}.png\"\n",
    "\n",
    "            attacked.save(out_path, optimize = True)\n",
    "\n",
    "            writer.writerow({**r,\n",
    "                             \"id\"        : uid,\n",
    "                             \"filename\"  : str(out_path),\n",
    "                             \"attack\"    : f\"resize_{int(s*100)}\",\n",
    "                             \"parent_id\" : r[\"id\"]\n",
    "                           })\n",
    "\n",
    "        # --- Blur ---\n",
    "        for b in BLUR_RADII:\n",
    "            attacked = blur_attack(img, b)\n",
    "            uid      = uuid.uuid4().hex\n",
    "            out_path = out_base / f\"{uid}.png\"\n",
    "\n",
    "            attacked.save(out_path, optimize = True)\n",
    "\n",
    "            writer.writerow({**r,\n",
    "                             \"id\"        : uid,\n",
    "                             \"filename\"  : str(out_path),\n",
    "                             \"attack\"    : f\"blur_{b}\",\n",
    "                             \"parent_id\" : r[\"id\"]\n",
    "                           })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3736496a-7710-4593-86fd-818b2d58d535",
   "metadata": {},
   "source": [
    "## Write Attack Metadata\n",
    "\n",
    "We preserve:\n",
    "- Original label (ai / real)\n",
    "- Source family\n",
    "- Parent image ID\n",
    "- Attack type\n",
    "\n",
    "This allows **per-attack evaluation later**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f29f49-4137-4752-a098-1eba404ce352",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(META_OUT, \"w\", newline = \"\") as f:\n",
    "    fieldnames = list(records[0].keys()) + [\"attack\", \"parent_id\"]\n",
    "    writer     = csv.DictWriter(f, fieldnames = fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    apply_attacks(records, writer)\n",
    "\n",
    "print(\"âœ… Post-processing attacks generated\")\n",
    "print(f\"Metadata saved to: {META_OUT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b8f36-af23-49b8-8c6b-d93cf2a7ba07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
